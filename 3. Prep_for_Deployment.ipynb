{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a940da-79a8-4003-b6c6-7631ddcae24e",
   "metadata": {},
   "source": [
    "## Module 10 -- Deployment -- Recap "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e109b9fd-4274-4c6b-97bd-17041e666b36",
   "metadata": {},
   "source": [
    "#### How to think before thinking of deploying - There're Several Critical Steps\n",
    "\n",
    "You got the broad strokes but a production pipeline needs to be exact. Missing one transformation = silent garbage predictions. No errors, just wrong numbers.\n",
    "> List the inference transformation steps in the correct order that raw input data must go through before hitting `model.predict()`.\n",
    "```\n",
    "Let me give you a hint. A customer places an order right now. We receive this JSON:\n",
    "{\n",
    "  \"created_at\": \"2025-02-20 19:30:00\",\n",
    "  \"market_id\": 3,\n",
    "  \"store_primary_category\": \"italian\",\n",
    "  \"order_protocol\": 1,\n",
    "  \"total_items\": 3,\n",
    "  \"subtotal\": 2500,\n",
    "  \"num_distinct_items\": 2,\n",
    "  \"min_item_price\": 600,\n",
    "  \"max_item_price\": 1200,\n",
    "  \"total_onshift_partners\": 12,\n",
    "  \"total_busy_partners\": 8,\n",
    "  \"total_outstanding_orders\": 15\n",
    "} \n",
    "```\n",
    ">  what happens to a single raw order JSON at prediction time. The sequence of data transformations.\n",
    "\n",
    "Here's the complete correct order:\n",
    "\n",
    "```\n",
    "1. Parse created_at → extract hour, day_of_week, month\n",
    "2. Engineer is_peak from hour\n",
    "3. Engineer time_period → encode using TRAINING category means\n",
    "4. Engineer demand_supply_ratio = outstanding_orders / (onshift + 1)\n",
    "5. Engineer price_range = max_item_price - min_item_price\n",
    "6. Engineer avg_item_price = subtotal / total_items\n",
    "7. Encode store_primary_category → training means (or global mean if unseen)\n",
    "8. One-hot encode market_id and order_protocol (drop_first=True)\n",
    "9. Drop store_id, created_at, raw datetime cols\n",
    "10. Apply log1p to: total_items, subtotal, min_item_price, \n",
    "                    max_item_price, total_outstanding_orders\n",
    "11. scaler.transform() — using saved scaler.pkl\n",
    "12. model.predict()\n",
    "13. np.expm1() → real minutes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3dc3f2-bb0a-40ac-9150-0987eec257eb",
   "metadata": {},
   "source": [
    "### Build the Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c19bf-6536-4211-9733-30021a0376f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68250f5a-f576-45a2-b20f-9361969d00aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpreprocess_input\u001b[39m(raw_input: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Transform raw order input through exact same pipeline as training.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Input:  raw order dictionary\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    Output: scaled numpy array ready for model.predict()\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Load artifacts\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def preprocess_input(raw_input: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Transform raw order input through exact same pipeline as training.\n",
    "    Input:  raw order dictionary\n",
    "    Output: scaled numpy array ready for model.predict()\n",
    "    \"\"\"\n",
    "    # Load artifacts\n",
    "    scaler = joblib.load('porter_model/scaler.pkl')\n",
    "    category_map = joblib.load('porter_model/category_encoding.pkl')\n",
    "    time_period_map = joblib.load('porter_model/time_period_encoding.pkl')\n",
    "    global_mean = joblib.load('porter_model/global_mean.pkl')\n",
    "    feature_cols = joblib.load('porter_model/feature_columns.pkl')\n",
    "    \n",
    "    # Work on a copy\n",
    "    data = raw_input.copy()\n",
    "    \n",
    "    # ── Step 1: Parse datetime ─────────────────────────────────────────\n",
    "    created_at = pd.to_datetime(data['created_at'])\n",
    "    data['hour'] = created_at.hour\n",
    "    data['day_of_week'] = created_at.dayofweek\n",
    "    data['month'] = created_at.month\n",
    "    \n",
    "    # ── Step 2: Time features ──────────────────────────────────────────\n",
    "    def get_time_period(hour):\n",
    "        if 6 <= hour <= 9: return 'breakfast'\n",
    "        elif 11 <= hour <= 14: return 'lunch'\n",
    "        elif 17 <= hour <= 21: return 'dinner'\n",
    "        elif hour in [22, 23, 0, 1]: return 'late_night'\n",
    "        else: return 'off_peak'\n",
    "    \n",
    "    data['is_peak'] = 1 if data['hour'] in [\n",
    "        11,12,13,14,15,19,20,21] else 0\n",
    "    time_period = get_time_period(data['hour'])\n",
    "    data['time_period_encoded'] = time_period_map.get(\n",
    "        time_period, global_mean)\n",
    "    data['is_weekend'] = 1 if data['day_of_week'] >= 5 else 0\n",
    "    \n",
    "    # ── Step 3: Category encoding ──────────────────────────────────────\n",
    "    category = data.get('store_primary_category', 'unknown')\n",
    "    data['category_encoded'] = category_map.get(\n",
    "        category, global_mean)\n",
    "    \n",
    "    # ── Step 4: Supply demand features ────────────────────────────────\n",
    "    data['demand_supply_ratio'] = (\n",
    "        data['total_outstanding_orders'] / \n",
    "        (data['total_onshift_partners'] + 1)\n",
    "    )\n",
    "    data['price_range'] = (\n",
    "        data['max_item_price'] - data['min_item_price'])\n",
    "    data['avg_item_price'] = (\n",
    "        data['subtotal'] / data['total_items'])\n",
    "    \n",
    "    # ── Step 5: Log1p transformations ─────────────────────────────────\n",
    "    for col in ['total_items', 'subtotal', 'min_item_price',\n",
    "                'max_item_price', 'total_outstanding_orders']:\n",
    "        data[col] = np.log1p(max(data[col], 0))\n",
    "    \n",
    "    # ── Step 6: One-hot encode market_id and order_protocol ───────────\n",
    "    for i in [2, 3, 4, 5, 6]:\n",
    "        data[f'market_id_{i}.0'] = 1 if data['market_id'] == i else 0\n",
    "    for i in [2, 3, 4, 5, 6, 7]:\n",
    "        data[f'order_protocol_{i}.0'] = (\n",
    "            1 if data['order_protocol'] == i else 0)\n",
    "    \n",
    "    # ── Step 7: Build dataframe in exact training column order ─────────\n",
    "    df_input = pd.DataFrame([data])\n",
    "    df_input = df_input[feature_cols]\n",
    "    \n",
    "    # ── Step 8: Scale ──────────────────────────────────────────────────\n",
    "    df_scaled = scaler.transform(df_input)\n",
    "    \n",
    "    return df_scaled\n",
    "\n",
    "def predict_delivery_time(raw_input: dict) -> dict:\n",
    "    \"\"\"\n",
    "    End to end prediction function.\n",
    "    Returns prediction in real minutes with confidence context.\n",
    "    \"\"\"\n",
    "    model = keras.models.load_model(\n",
    "        'porter_model/best_model_v2.keras')\n",
    "    \n",
    "    # Preprocess\n",
    "    X = preprocess_input(raw_input)\n",
    "    \n",
    "    # Predict in log space\n",
    "    y_log = model.predict(X, verbose=0).flatten()[0]\n",
    "    \n",
    "    # Inverse transform to real minutes\n",
    "    y_minutes = float(np.expm1(y_log))\n",
    "    \n",
    "    # Clamp to realistic range\n",
    "    y_minutes = max(5.0, min(120.0, y_minutes))\n",
    "    \n",
    "    return {\n",
    "        'predicted_delivery_minutes': round(y_minutes, 1),\n",
    "        'predicted_delivery_range': {\n",
    "            'optimistic': round(max(5.0, y_minutes - 10), 1),\n",
    "            'pessimistic': round(min(120.0, y_minutes + 10), 1)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ── Test the pipeline ──────────────────────────────────────────────────\n",
    "test_order = {\n",
    "    \"created_at\": \"2015-02-15 19:30:00\",\n",
    "    \"market_id\": 3,\n",
    "    \"store_primary_category\": \"italian\",\n",
    "    \"order_protocol\": 1,\n",
    "    \"total_items\": 3,\n",
    "    \"subtotal\": 2500,\n",
    "    \"num_distinct_items\": 2,\n",
    "    \"min_item_price\": 600,\n",
    "    \"max_item_price\": 1200,\n",
    "    \"total_onshift_partners\": 12,\n",
    "    \"total_busy_partners\": 8,\n",
    "    \"total_outstanding_orders\": 15\n",
    "}\n",
    "\n",
    "result = predict_delivery_time(test_order)\n",
    "print(\"Test prediction:\")\n",
    "print(f\"  Predicted: {result['predicted_delivery_minutes']} minutes\")\n",
    "print(f\"  Range: {result['predicted_delivery_range']['optimistic']}\"\n",
    "      f\" - {result['predicted_delivery_range']['pessimistic']} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00973c6-1dfe-4da1-9f3c-f86e0006ffb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
